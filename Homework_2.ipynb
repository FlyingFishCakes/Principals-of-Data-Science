{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Kevin Lin\n",
        "\n",
        "Data 602, Homework 2\n"
      ],
      "metadata": {
        "id": "4rQIUxo1xttt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import required modules"
      ],
      "metadata": {
        "id": "pSk2UfQOWCIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.decomposition import PCA\n",
        "from pathlib import Path\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "50XkEZRoWBlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Data\n",
        "First import the images and turn them into 1 dimensional vectors and create a list of their corresponding labels from the file names."
      ],
      "metadata": {
        "id": "SYt1Wdezx4B7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-KEoKkKhxn40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "905143be-bf28-4338-bb42-9ce7f7f53511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images: 400 \n",
            "Image Vector Length: 10304 \n",
            "Labels: 400\n",
            "Label: 33 | Image: [ 93  92  98 ... 118 119 130]\n"
          ]
        }
      ],
      "source": [
        "# Unzip the data set\n",
        "file_path = '/content/Face Data for Homework.zip'\n",
        "with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/')\n",
        "\n",
        "# Remove the text file contained in the folder\n",
        "if os.path.exists('/content/ATT/README'):\n",
        "    os.remove('/content/ATT/README')\n",
        "\n",
        "# Read each image row by row and turn into a 1D list and then append to a 2D list of all the images for a subject\n",
        "# Also get the Label for the image from the filename (ie. '10_2.png' is label_count.png) and use the label as the index in the list of lists\n",
        "vector_images = []\n",
        "vector_labels = []\n",
        "for image_file in Path('/content/ATT').glob('*.png'):\n",
        "    vector_labels.append(int(image_file.stem.split('_')[0]))\n",
        "    with Image.open(image_file) as image:\n",
        "      vector_images.append(np.array(image).flatten())\n",
        "\n",
        "print(\"Images:\", len(vector_images), \"\\nImage Vector Length:\", len(vector_images[0]), \"\\nLabels:\", len(vector_labels))\n",
        "print(\"Label:\", vector_labels[0], \"| Image:\", vector_images[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement 5-Fold Cross-Validation (Stratified)\n",
        "We need to shuffle the images within their corresponding labels so there the same amount of training and testing images for all 40 subjects. This will give 8 photos for training and 2 testing photos per person for a total of 320 training photos and 80 testing photos per fold.\n",
        "\n",
        "---\n",
        "\n",
        "Then for each fold implement the Eigenfaces (PCA) Method to prepare the dataset to be used for kNN where k = 1.\n",
        "\n",
        "---\n",
        "\n",
        "Test and display results for each fold. Then aggregate and average the results at the end (we are asked for average prediction accuracy which is TP/(TP+FP))."
      ],
      "metadata": {
        "id": "Ov-2WsQWObI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make our own kNN classifier\n",
        "def ONEnn_predict(X_train, y_train, X_test):\n",
        "    # Distance is Euclidean norm between test point and all of training set samples\n",
        "    distances = np.linalg.norm(X_train - X_test, axis=1)\n",
        "\n",
        "    # Sort the distances to find the lowest value/closest point\n",
        "    sorted_indices = np.argsort(distances)\n",
        "\n",
        "    # Get and return the label of the closest point\n",
        "    return y_train[sorted_indices[0]]"
      ],
      "metadata": {
        "id": "Pihg6g4gEcHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the builtin StratifiedKFold to divide the folds\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# Convert vector_images and vector_labels into numpy arrays\n",
        "vector_images = np.array(vector_images)\n",
        "vector_labels = np.array(vector_labels)\n",
        "\n",
        "# For each fold implement the Eigenfaces (PCA) Method, and then test on the testing dataset\n",
        "results = []\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(vector_images, vector_labels), 1):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test = vector_images[train_index], vector_images[test_index]\n",
        "    y_train, y_test = vector_labels[train_index], vector_labels[test_index]\n",
        "\n",
        "    # Perform PCA on the training data\n",
        "    # X_train is 320x10304 2D list, I will end up with 320 possible principal components\n",
        "    # I have to choose from within the range [1, 320]\n",
        "    pca = PCA(n_components=40)\n",
        "    X_train_pca = pca.fit_transform(X_train)\n",
        "    X_test_pca = pca.transform(X_test)\n",
        "\n",
        "    # Loop through each transformed test point and their corresponding test label, tally the correct predictions\n",
        "    correct_predictions = 0\n",
        "    for test_point, test_label in zip(X_test_pca, y_test):\n",
        "        # Predict the label for the test point\n",
        "        y_pred = ONEnn_predict(X_train_pca, y_train, test_point)\n",
        "        # Check if the prediction is correct\n",
        "        if y_pred == test_label:\n",
        "            correct_predictions += 1\n",
        "\n",
        "    # Calculate the accuracy for this fold (TP + FP I realize is just the length of 1 fold)\n",
        "    accuracy = correct_predictions / len(y_test)\n",
        "    results.append(accuracy)\n",
        "\n",
        "    # Display the results for each of the folds\n",
        "    print(f\"Fold {fold}: Accuracy = {accuracy}\")\n",
        "\n",
        "\n",
        "# Aggregate the results at the end\n",
        "average_accuracy = np.mean(results)\n",
        "print(f\"Average Accuracy: {average_accuracy}\")"
      ],
      "metadata": {
        "id": "ZJrNLto8PGat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8de81a-314e-47c4-dc83-6c7a642ccc95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1: Accuracy = 1.0\n",
            "Fold 2: Accuracy = 0.975\n",
            "Fold 3: Accuracy = 0.9625\n",
            "Fold 4: Accuracy = 0.9625\n",
            "Fold 5: Accuracy = 0.9875\n",
            "Average Accuracy: 0.9775\n"
          ]
        }
      ]
    }
  ]
}